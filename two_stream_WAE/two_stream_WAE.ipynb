{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of UTwo-stream WAE for SVHN <−−> MNIST transfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage import color, transform\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "folder_mnist = \"/ext/czh/two_stream_WAE/datasets/mnist\"\n",
    "folder_svhn = \"/ext/czh/two_stream_WAE/datasets/svhn\"\n",
    "download_svhn = True # mnist is automatically downloaded if not in the folder\n",
    "\n",
    "colormap = np.array(plt.rcParams['axes.prop_cycle'].by_key()['color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x, max_value):\n",
    "    \"\"\" If x takes its values between 0 and max_value, normalize it between -1 and 1\"\"\"\n",
    "    return (x / float(max_value)) * 2 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVHN\n",
    "\n",
    "We follow the methodology of [1] and use the \"extra\" SVHN set as the training set. The test set can be useful for evaluations beyond the paper.\n",
    "\n",
    "Concerning the transformation, we turn the 32x32 RGB images and normalize them between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /ext/czh/UNIT-mnist-svhn-master/datasets/svhn/extra_32x32.mat\n",
      "Using downloaded and verified file: /ext/czh/UNIT-mnist-svhn-master/datasets/svhn/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "svhn_train = datasets.SVHN(root=folder_svhn, download=download_svhn, split=\"extra\")\n",
    "svhn_test = datasets.SVHN(root=folder_svhn, download=download_svhn, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_svhn(X):\n",
    "    X = np.transpose(X, (0,2,3,1))\n",
    "    X = np.array([color.rgb2gray(im) for im in X])\n",
    "    X = normalize(X, 1)\n",
    "    X = X.reshape(len(X), 32, 32, 1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming SVHN train...\n",
      "Transforming SVHN test...\n"
     ]
    }
   ],
   "source": [
    "print(\"Transforming SVHN train...\")\n",
    "X_svhn_train = transform_svhn(svhn_train.data)\n",
    "\n",
    "print(\"Transforming SVHN test...\")\n",
    "X_svhn_test = transform_svhn(svhn_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lb_svhn = LabelBinarizer()\n",
    "\n",
    "Y_svhn_train = lb_svhn.fit_transform(svhn_train.labels.flatten() % 10)\n",
    "Y_svhn_test = lb_svhn.fit_transform(svhn_test.labels.flatten() % 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST\n",
    "\n",
    "Translate 28x28 grayscale images to 32x32 RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /ext/czh/UNIT-mnist-svhn-master/datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /ext/czh/UNIT-mnist-svhn-master/datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /ext/czh/UNIT-mnist-svhn-master/datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /ext/czh/UNIT-mnist-svhn-master/datasets/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(folder_mnist, one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_mnist(X):\n",
    "    X = X.reshape(len(X), 28, 28)\n",
    "    X = np.array([transform.resize(im, [32,32]) for im in X])\n",
    "    X = normalize(X, 1)\n",
    "    X = X.reshape(len(X), 32, 32, 1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming MNIST train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/czh/software/conda/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming MNIST test...\n"
     ]
    }
   ],
   "source": [
    "print(\"Transforming MNIST train...\")\n",
    "X_mnist_train = transform_mnist(mnist.train.images)\n",
    "\n",
    "print(\"Transforming MNIST test...\")\n",
    "X_mnist_test = transform_mnist(mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lb_mnist = LabelBinarizer()\n",
    "\n",
    "Y_mnist_train = lb_mnist.fit_transform(mnist.train.labels)\n",
    "Y_mnist_test = lb_mnist.fit_transform(mnist.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_source = X_svhn_train\n",
    "Y_source = Y_svhn_train\n",
    "\n",
    "X_target = X_mnist_train\n",
    "X_target_test = X_mnist_test\n",
    "Y_target_test = Y_mnist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    alpha = 0.05\n",
    "    return tf.maximum(x, alpha * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for instance normalization [1] adapted from [here](https://github.com/rickbarraza/tensorflow-cyclegan/blob/master/cyclegan.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instance_normalization(x, name):\n",
    "    with tf.variable_scope(\"instance_norm\"):\n",
    "        with tf.variable_scope(name):\n",
    "            epsilon = 1e-5\n",
    "            mean, var = tf.nn.moments(x, [1, 2], keep_dims=True)\n",
    "            scale = tf.get_variable('scale',[x.get_shape()[-1]], \n",
    "                                    initializer=tf.truncated_normal_initializer(mean=1.0, stddev=0.02))\n",
    "            offset = tf.get_variable('offset',[x.get_shape()[-1]],initializer=tf.constant_initializer(0.0))\n",
    "            out = scale*tf.div(x-mean, tf.sqrt(var+epsilon)) + offset\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipt_source = tf.placeholder(tf.float32, shape=[None, 32, 32, 1], name='ipt_source')\n",
    "ipt_target = tf.placeholder(tf.float32, shape=[None, 32, 32, 1], name='ipt_target')\n",
    "labels_source = tf.placeholder(tf.int32, shape=[None, 10], name=\"labels_source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator has two roles: separating real from generated samples, and classifying the MNIST digits.\n",
    "\n",
    "The first layer's weights depend on the task (source to target or target to source), while all the other layers have shared weights. Indeed, \"this allows us to adapt a classifier trained in the source domain to the target\n",
    "domain.\" [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x, scope,reuses1,reuses2):\n",
    "    \"\"\"Discriminator for the two GANs, and source classifier\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : tensor of shape = [?, 32, 32, 1]\n",
    "        Either the input (real sample) or the generated image (fake sample)\n",
    "    scope : {'source', 'target'}\n",
    "        Choose 'source' for separating real_source from fake_source and 'target' for separating real_target from\n",
    "        fake_target. Only used for the first layer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fc1_sigmoid : tensor of shape = [1]\n",
    "        Output of the discriminator real vs fake with a sigmoid\n",
    "    fc1_logits : tensor of shape = [1]\n",
    "        Output of the discriminator real vs fake without any activation function\n",
    "    fc1_classif : tensor of shape = [10]\n",
    "        Output of the source classifier, without any activation (softmax used after in the loss)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "    with tf.variable_scope(scope + \"/discriminator\", reuse=reuses1):\n",
    "        # Layer 1: 32x32x1 --> 16x16x64 (n=1 or 3)\n",
    "        conv1 = tf.layers.conv2d(x, 64, [5,5], strides=2, padding='SAME', kernel_initializer=initializer, activation=leaky_relu)\n",
    "        conv1 = instance_normalization(conv1, \"conv1\")\n",
    "        \n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuses2):\n",
    "        # Layer 2: 16x16x64 --> 8x8x128        \n",
    "        conv2 = tf.layers.conv2d(conv1, 128, [5,5], strides=2, padding='SAME', kernel_initializer=initializer, activation=leaky_relu)\n",
    "        conv2 = instance_normalization(conv2, \"conv2\")\n",
    "        \n",
    "        # Layer 3: 8x8x128 --> 4x4x256    \n",
    "        conv3 = tf.layers.conv2d(conv2, 256, [5,5], strides=2, padding='SAME', kernel_initializer=initializer, activation=leaky_relu)\n",
    "        conv3 = instance_normalization(conv3, \"conv3\")\n",
    "        \n",
    "        # Layer 4: 4x4x256 --> 2x2x512    \n",
    "        conv4 = tf.layers.conv2d(conv3, 512, [5,5], strides=2, padding='SAME', kernel_initializer=initializer, activation=leaky_relu)\n",
    "        conv4 = instance_normalization(conv4, \"conv4\")\n",
    "\n",
    "        # Layer 3: 2x2x512 --> 1\n",
    "        fc1 = tf.contrib.layers.flatten(conv4)\n",
    "        fc1_logits = tf.layers.dense(inputs=fc1, units=1, activation=None, kernel_initializer=initializer)\n",
    "        fc1_sigmoid = tf.sigmoid(fc1_logits)\n",
    "        fc1_classif = tf.layers.dense(inputs=fc1, units=10, activation=None, kernel_initializer=initializer)\n",
    "        \n",
    "    return fc1_sigmoid, fc1_logits, fc1_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Network\n",
    "\n",
    "Transform either source or target samples to the embedding space. Since the encoder is part of a VAE, the embedding space corresponds to a gaussian with mean $\\mu(x)$ and variance $\\sigma^2(x)$. The encoder outputs $\\mu$ and $log(\\sigma^2)$, but returns also a random tensor sampled from this gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder(x, scope,reuses):\n",
    "    \"\"\"Encoder for the two GANs\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : tensor of shape = [?, 32, 32, 1]\n",
    "        Normally takes a real image (except if you use cycle-consistency)\n",
    "    scope : {'source', 'target'}\n",
    "        Corresponds to the domain of x\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mu : tensor of shape = [?, 8, 8, 1024]\n",
    "        Mean of the embedding space conditionned on x\n",
    "    log_sigma_sq : tensor of shape = [?, 8, 8, 1024]\n",
    "        log of the variance of the embedding space conditionned on x\n",
    "    z : tensor of shape = [?, 8, 8, 1024]\n",
    "        Random sample generated from mu(x) and sigma(x)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    \n",
    "    with tf.variable_scope(scope + \"/encoder\", reuse=None): # not shared\n",
    "        # Layer 1: 32x32x1 --> 16x16x64\n",
    "        conv1 = tf.layers.conv2d(x, 64, [5, 5], strides=2, padding='SAME', \n",
    "                                 kernel_initializer=initializer, activation=leaky_relu)\n",
    "        conv1 = instance_normalization(conv1, \"conv1\")\n",
    "    \n",
    "    with tf.variable_scope(\"encoder\", reuse=reuses): # shared weights\n",
    "        # Layer 2: 16x16x64 --> 8x8x128\n",
    "        conv2 = tf.layers.conv2d(conv1, 128, [5, 5], strides=2, padding='SAME', \n",
    "                                 kernel_initializer=initializer, activation=leaky_relu)\n",
    "        conv2 = instance_normalization(conv2, \"conv2\")\n",
    "        \n",
    "        # Layer 3: 8x8x128 --> 8x8x256\n",
    "        conv3 = tf.layers.conv2d(conv2, 256, [8, 8], strides=1, padding='SAME', \n",
    "                                 kernel_initializer=initializer, activation=leaky_relu)\n",
    "        conv3 = instance_normalization(conv3, \"conv3\")\n",
    "        \n",
    "        # Layer 4: 8x8x256 --> 8x8x512\n",
    "        conv4 = tf.layers.conv2d(conv3, 512, [1, 1], strides=1, padding='SAME', \n",
    "                                 kernel_initializer=initializer, activation=leaky_relu)\n",
    "        conv4 = instance_normalization(conv4, \"conv4\")\n",
    "\n",
    "        # Layer 5 : 8x8x512 --> 8x8x1024\n",
    "        mu = tf.layers.conv2d(conv4, 1024, [1, 1], strides=1, padding='SAME', \n",
    "                              kernel_initializer=initializer, activation=None)\n",
    "        log_sigma_sq = tf.layers.conv2d(conv4, 1024, [1, 1], strides=1, padding='SAME', \n",
    "                              kernel_initializer=initializer, activation=None)\n",
    "        \n",
    "        z = mu + tf.multiply(tf.exp(log_sigma_sq / 2), tf.random_normal([tf.shape(x)[0],8,8,1024],0,1,dtype=tf.float32)) # latent space\n",
    "        \n",
    "    return mu, log_sigma_sq, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network\n",
    "\n",
    "Transform the embedding space to the source or target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, scope,reuses1,reuses2):\n",
    "    \"\"\"Generator for the two GANs\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : tensor of shape = [?, 8, 8, 1024]\n",
    "        Normally takes an encoded image (point in the embedding space)\n",
    "    scope : {'source', 'target'}\n",
    "        Corresponds to the domain of x\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    deconv5 : tensor of shape = [?, 32, 32, 1]\n",
    "        Generated image\n",
    "    \"\"\"\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    \n",
    "    with tf.variable_scope(\"generator\", reuse=reuses1): # shared weights\n",
    "        # Layer 1: 8x8x1024 --> 16x16x512\n",
    "        deconv1 = tf.layers.conv2d_transpose(z, 512, [4, 4], strides=2, padding='SAME', kernel_initializer=initializer, activation=leaky_relu)\n",
    "        deconv1 = instance_normalization(deconv1, \"deconv1\")\n",
    "        \n",
    "        # Layer 2: 16x16x512 --> 32x32x256\n",
    "        deconv2 = tf.layers.conv2d_transpose(deconv1, 256, [4, 4], strides=2, padding='SAME', kernel_initializer=initializer, activation=leaky_relu)\n",
    "        deconv2 = instance_normalization(deconv2, \"deconv2\")\n",
    "        \n",
    "        # Layer 3: 32x32x256 --> 32x32x128\n",
    "        deconv3 = tf.layers.conv2d_transpose(deconv2, 128, [4, 4], strides=1, padding='SAME', kernel_initializer=initializer, activation=leaky_relu)\n",
    "        deconv3 = instance_normalization(deconv3, \"deconv3\")\n",
    "        \n",
    "    with tf.variable_scope(scope + \"/generator\", reuse=reuses2):\n",
    "        # Layer 3: 32x32x128 --> 32x32x64\n",
    "        deconv4 = tf.layers.conv2d_transpose(deconv3, 64, [4, 4], strides=1, padding='SAME', kernel_initializer=initializer, activation=leaky_relu)\n",
    "        deconv4 = instance_normalization(deconv4, \"deconv4\")\n",
    "\n",
    "        # Layer 6: 32x32x64 --> 32x32x1\n",
    "        deconv5 = tf.layers.conv2d_transpose(deconv4, 1, [1, 1], strides=1, padding='SAME', kernel_initializer=initializer, activation=tf.nn.tanh)\n",
    "        \n",
    "    return deconv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(tensor):\n",
    "    return tf.log(tensor + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "E_mean_source, E_log_sigma_sq_source, E_source = encoder(ipt_source, \"source\",None)\n",
    "E_mean_target, E_log_sigma_sq_target, E_target = encoder(ipt_target, \"target\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GAN\n",
    "G_t2s = generator(E_target, \"source\",None,None) # target to source (t2s)\n",
    "G_s2t = generator(E_source, \"target\",True,None) # source to target (s2t)\n",
    "\n",
    "# VAE\n",
    "G_t2t = generator(E_target, \"target\",True,True) # target to target (t2t)\n",
    "G_s2s = generator(E_source, \"source\",True,True) # source to source (s2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_target, D_target_logits, D_target_classif = discriminator(ipt_target, \"target\",None,None)\n",
    "D_source, D_source_logits, D_source_classif = discriminator(ipt_source, \"source\",None,True)\n",
    "\n",
    "DG_t2s, DG_t2s_logits, DG_t2s_classif = discriminator(G_t2s, \"source\",True,True)\n",
    "DG_s2t, DG_s2t_logits, DG_s2t_classif = discriminator(G_s2t, \"target\",True,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VAE losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source : [Variational Autoencoder: Intuition and Implementation](https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambda_rec = 1\n",
    "lambda_kl = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruction_loss(x, x_rec):\n",
    "    x, x_rec = normalize(x), normalize(x_rec)\n",
    "    return - tf.reduce_mean(x * log(x_rec) + (1 - x) * log(1 - x_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def latent_loss(mean, log_std_sq):\n",
    "    return 0.5 * tf.reduce_mean(tf.square(mean) + tf.exp(log_std_sq) - log_std_sq - 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae_s2s_loss = lambda_rec * reconstruction_loss(ipt_source, G_s2s) \\\n",
    "               + lambda_kl * latent_loss(E_mean_source, E_log_sigma_sq_source)\n",
    "vae_t2t_loss = lambda_rec * reconstruction_loss(ipt_target, G_t2t) \\\n",
    "               + lambda_kl * latent_loss(E_mean_target, E_log_sigma_sq_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambda_classif = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classif_source_loss = lambda_classif * tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels_source, \n",
    "                                                                                              logits=D_source_classif))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN losses\n",
    "\n",
    "See [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wasserstein_disc_loss(D_real, D_gen):\n",
    "    \"\"\" Warning : take logits as input\"\"\"\n",
    "    return tf.reduce_mean(D_gen) - tf.reduce_mean(D_real)\n",
    "\n",
    "def wasserstein_gen_loss(D_gen):\n",
    "    \"\"\" Warning : take logits as input\"\"\"\n",
    "    return -tf.reduce_mean(D_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_s2t_loss = wasserstein_disc_loss(D_target_logits, DG_s2t_logits)\n",
    "G_s2t_loss = wasserstein_gen_loss(DG_s2t_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_t2s_loss = wasserstein_disc_loss(D_source_logits, DG_t2s_logits)\n",
    "G_t2s_loss = wasserstein_gen_loss(DG_t2s_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vars = tf.trainable_variables()\n",
    "\n",
    "D_s2t_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target/discriminator') \\\n",
    "             + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "\n",
    "D_t2s_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='source/discriminator') \\\n",
    "             + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "\n",
    "G_s2t_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='source/encoder') \\\n",
    "             + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target/generator') \\\n",
    "             + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator') \\\n",
    "             + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='encoder')\n",
    "G_t2s_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target/encoder') \\\n",
    "             + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='source/generator') \\\n",
    "             + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator') \\\n",
    "             + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='encoder')\n",
    "            \n",
    "\n",
    "vae_s2s_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='source/encoder') \\\n",
    "               + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='source/generator') \\\n",
    "               + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator') \\\n",
    "               + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='encoder')\n",
    "vae_t2t_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target/encoder') \\\n",
    "               + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target/generator') \\\n",
    "               + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator') \\\n",
    "               + tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"optim\", reuse=None):\n",
    "    D_s2t_solver = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(D_s2t_loss, var_list=D_s2t_vars)\n",
    "    G_s2t_solver = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(G_s2t_loss, var_list=G_s2t_vars)\n",
    "    D_t2s_solver = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(D_t2s_loss, var_list=D_t2s_vars)\n",
    "    G_t2s_solver = tf.train.RMSPropOptimizer(learning_rate=5e-5).minimize(G_t2s_loss, var_list=G_t2s_vars)\n",
    "\n",
    "    classif_source_solver = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(classif_source_loss, \n",
    "                                                                                var_list=D_t2s_vars)\n",
    "\n",
    "    vae_s2s_solver = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(vae_s2s_loss, var_list=vae_s2s_vars)\n",
    "    vae_t2t_solver = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(vae_t2t_loss, var_list=vae_t2t_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clipping for Wasserstein loss [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip_D_s2t = [p.assign(tf.clip_by_value(p, -0.1, 0.1)) for p in D_s2t_vars]\n",
    "clip_D_t2s = [p.assign(tf.clip_by_value(p, -0.1, 0.1)) for p in D_t2s_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=False))\n",
    "gpu_options=tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "D_s2t_loss_list = []\n",
    "G_s2t_loss_list = []\n",
    "D_t2s_loss_list = []\n",
    "G_t2s_loss_list = []\n",
    "vae_s2s_loss_list = []\n",
    "vae_t2t_loss_list = []\n",
    "classif_t2s_loss_list = []\n",
    "accuracy_list = []\n",
    "iter_list = []\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"model/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D_s2t_loss_list = list(np.loadtxt(\"D_s2t_loss_list.txt\"))\n",
    "# G_s2t_loss_list = list(np.loadtxt(\"G_s2t_loss_list.txt\"))\n",
    "# D_t2s_loss_list = list(np.loadtxt(\"D_t2s_loss_list.txt\"))\n",
    "# G_t2s_loss_list = list(np.loadtxt(\"G_t2s_loss_list.txt\"))\n",
    "# vae_s2s_loss_list = list(np.loadtxt(\"vae_s2s_loss_list.txt\"))\n",
    "# vae_t2t_loss_list = list(np.loadtxt(\"vae_t2t_loss_list.txt\"))\n",
    "# iter_list = list(np.loadtxt(\"iter_list.txt\"))\n",
    "# i = len(iter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 499 / 499\n",
      "D loss s2t: -38.15\n",
      "D loss t2s: -23.19\n",
      "G loss s2t: 19.64\n",
      "G loss t2s: 16.18\n",
      "VAE loss s2s: 0.6686\n",
      "VAE loss t2t: 0.1352\n",
      "Classif loss : 0.3188\n",
      "()\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "nb_iter = 500\n",
    "nb_iter_d = 5\n",
    "nb_iter_vae = 1\n",
    "nb_iter_g = 1\n",
    "nb_iter_classif = 2\n",
    "verbose = True\n",
    "\n",
    "i_init = i\n",
    "for i in range(i, nb_iter+i):\n",
    "    for k in range(nb_iter_vae):\n",
    "        sample_source = X_source[np.random.choice(len(X_source), batch_size)]\n",
    "        sample_target = X_target[np.random.choice(len(X_target), batch_size)]\n",
    "        \n",
    "        ## Optimizing VAE s2s\n",
    "        _, vae_s2s_loss_curr = sess.run([vae_s2s_solver, vae_s2s_loss], feed_dict={ipt_source: sample_source})\n",
    "        _, vae_t2t_loss_curr = sess.run([vae_t2t_solver, vae_t2t_loss], feed_dict={ipt_target: sample_target})\n",
    "        \n",
    "    for k in range(nb_iter_g):\n",
    "        sample_source = X_source[np.random.choice(len(X_source), batch_size)]\n",
    "        sample_target = X_target[np.random.choice(len(X_target), batch_size)]\n",
    "        \n",
    "        # Optimizing gen s2t\n",
    "        _, G_s2t_loss_curr = sess.run([G_s2t_solver, G_s2t_loss], feed_dict={ipt_source: sample_source, \n",
    "                                                                             ipt_target: sample_target})\n",
    "    \n",
    "        ## Optimizing gen t2s\n",
    "        _, G_t2s_loss_curr = sess.run([G_t2s_solver, G_t2s_loss], feed_dict={ipt_source: sample_source, \n",
    "                                                                             ipt_target: sample_target})\n",
    "        \n",
    "    for k in range(nb_iter_d):\n",
    "        sample_source = X_source[np.random.choice(len(X_source), batch_size)]\n",
    "        sample_target = X_target[np.random.choice(len(X_target), batch_size)]\n",
    "        \n",
    "        # Optimizing s2t\n",
    "        _, D_s2t_loss_curr,_ = sess.run([D_s2t_solver, D_s2t_loss, clip_D_s2t], feed_dict={ipt_source: sample_source, \n",
    "                                                                                           ipt_target: sample_target})\n",
    "    \n",
    "        ## Optimizing t2s\n",
    "        _, D_t2s_loss_curr,_ = sess.run([D_t2s_solver, D_t2s_loss, clip_D_t2s], feed_dict={ipt_source: sample_source, \n",
    "                                                                                           ipt_target: sample_target})\n",
    "        \n",
    "        \n",
    "    for k in range(nb_iter_classif):\n",
    "        idx_sample_source = np.random.choice(len(X_source), batch_size)\n",
    "        sample_source = X_source[idx_sample_source]\n",
    "        sample_source_labels = Y_source[idx_sample_source]\n",
    "        sample_target = X_target[np.random.choice(len(X_target), batch_size)]\n",
    "        \n",
    "        _, classif_t2s_loss_curr = sess.run([classif_source_solver, classif_source_loss], feed_dict={ipt_source: sample_source, \n",
    "                                                                                                     labels_source: sample_source_labels})\n",
    "        \n",
    "    iter_list.append(i)\n",
    "    D_s2t_loss_list.append(D_s2t_loss_curr)\n",
    "    G_s2t_loss_list.append(G_s2t_loss_curr)\n",
    "    D_t2s_loss_list.append(D_t2s_loss_curr)\n",
    "    G_t2s_loss_list.append(G_t2s_loss_curr)\n",
    "    vae_s2s_loss_list.append(vae_s2s_loss_curr)\n",
    "    vae_t2t_loss_list.append(vae_t2t_loss_curr)\n",
    "    classif_t2s_loss_list.append(classif_t2s_loss_curr)\n",
    "    \n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print('Iter: {} / {}'.format(i, i_init + nb_iter - 1))\n",
    "        print('D loss s2t: {:.4}'.format(D_s2t_loss_curr))\n",
    "        print('D loss t2s: {:.4}'.format(D_t2s_loss_curr))\n",
    "        print('G loss s2t: {:.4}'.format(G_s2t_loss_curr))\n",
    "        print('G loss t2s: {:.4}'.format(G_t2s_loss_curr))\n",
    "        print('VAE loss s2s: {:.4}'.format(vae_s2s_loss_curr))\n",
    "        print('VAE loss t2t: {:.4}'.format(vae_t2t_loss_curr))\n",
    "        print('Classif loss : {:.4}'.format(classif_t2s_loss_curr))\n",
    "        print()\n",
    "\n",
    "#     if i % (nb_iter//20) == 0:\n",
    "print(\"Saving model...\")\n",
    "saver.save(sess, \"model/model.ckpt\")\n",
    "np.savetxt(\"D_s2t_loss_list.txt\", D_s2t_loss_list)\n",
    "np.savetxt(\"G_s2t_loss_list.txt\", G_s2t_loss_list)\n",
    "np.savetxt(\"D_t2s_loss_list.txt\", D_t2s_loss_list)\n",
    "np.savetxt(\"G_t2s_loss_list.txt\", G_t2s_loss_list)\n",
    "np.savetxt(\"vae_s2s_loss_list.txt\", vae_s2s_loss_list)\n",
    "np.savetxt(\"vae_t2t_loss_list.txt\", vae_t2t_loss_list)\n",
    "np.savetxt(\"classif_t2s_loss_list.txt\", classif_t2s_loss_list)\n",
    "np.savetxt(\"iter_list.txt\", iter_list)\n",
    "\n",
    "# summary_writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unnormalize(x):\n",
    "    return (x + 1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_s2s = unnormalize(sess.run(G_s2s, feed_dict={ipt_source: X_source[:batch_size]}))\n",
    "# X_s2s = unnormalize(sess.run(generator(E_mean_source + tf.random_normal([batch_size,8,8,1024],0,1,dtype=tf.float32), \"source\"), feed_dict={ipt_source: X_source[:batch_size]}))\n",
    "X_t2t = unnormalize(sess.run(G_t2t, feed_dict={ipt_target: X_target[:batch_size]}))\n",
    "X_s2t = unnormalize(sess.run(G_s2t, feed_dict={ipt_source: X_source[:batch_size]}))\n",
    "X_t2s = unnormalize(sess.run(G_t2s, feed_dict={ipt_target: X_target[:batch_size]}))\n",
    "\n",
    "Y_source_predict = np.argmax(sess.run(tf.nn.softmax(D_source_classif), feed_dict={ipt_source: X_source[:batch_size]}), axis=1)\n",
    "Y_target_predict = np.argmax(sess.run(tf.nn.softmax(DG_t2s_classif), feed_dict={ipt_target: X_target[:batch_size]}), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAJOCAYAAADGYfSfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAKo1EDAAAojEYNAACgMBo1AACAwvwXf+nxeAfEr/MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c0c0a2950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "# plt.axes().set_aspect('equal', 'datalim')\n",
    "#plt.axis([-3,3,-3,3])\n",
    "\n",
    "index = 3\n",
    "plt.subplot(2,3,1)\n",
    "plt.title(Y_source_predict[index])\n",
    "plt.imshow(X_source[index].reshape(32,32))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(X_s2t[index].reshape(32,32))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(X_s2s[index].reshape(32,32))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.title(Y_target_predict[index])\n",
    "plt.imshow(X_target[index].reshape(32,32))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(X_t2s[index].reshape(32,32))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "#plt.imshow(np.transpose(X_target_trans[index].reshape(3,32,32), (1,2,0)))\n",
    "plt.imshow(X_t2t[index].reshape(32,32))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-c097f740ac6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_s2t_loss_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Discriminator loss − s2t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_t2s_loss_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Discriminator loss − t2s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-c097f740ac6d>\u001b[0m in \u001b[0;36msmooth\u001b[0;34m(x_list)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGfCAYAAAB1KinVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nchIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ba5d69590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 10\n",
    "start = 0\n",
    "def smooth(x_list):\n",
    "    res = [np.sum([x_list[k+j] for j in range(-k, k+1)])]\n",
    "    for i in range(k+1, len(x_list)-k):\n",
    "        res.append(res[-1] - x_list[i-k-1] + x_list[i+k])\n",
    "    return np.array(res) / (2 * k)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 7)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(iter_list[k+start:-k], smooth(D_s2t_loss_list[start:]), label=\"Discriminator loss − s2t\")\n",
    "plt.plot(iter_list[k+start:-k], smooth(D_t2s_loss_list[start:]), label=\"Discriminator loss − t2s\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(iter_list[k+start:-k], smooth(G_s2t_loss_list[start:]), label=\"Generator loss − s2t\")\n",
    "plt.plot(iter_list[k+start:-k], smooth(G_t2s_loss_list[start:]), label=\"Generator loss − t2s\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VAE losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-4f5cf0ff0c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae_s2s_loss_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"VAE s2s loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-c097f740ac6d>\u001b[0m in \u001b[0;36msmooth\u001b[0;34m(x_list)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGfCAYAAAB1KinVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nchIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0af5d8e410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 0\n",
    "k = 10\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(iter_list[k+start:-k], smooth(vae_s2s_loss_list[start:]), label=\"VAE s2s loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(iter_list[k+start:-k], smooth(vae_t2t_loss_list[start:]), label=\"VAE t2t loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-aaf696f568e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassif_t2s_loss_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Classif loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-c097f740ac6d>\u001b[0m in \u001b[0;36msmooth\u001b[0;34m(x_list)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "k = 10\n",
    "plt.plot(iter_list[k+start:-k], smooth(classif_t2s_loss_list[start:]), label=\"Classif loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-82443bfcc6eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy of target classification on the test set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-c097f740ac6d>\u001b[0m in \u001b[0;36msmooth\u001b[0;34m(x_list)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIkAAAGrCAYAAABE7sfCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xvc5nVd5/H3xxkPeURhMh1QSfGAB1wdwVpLKjeBLGof\nHUCTNIsHu9Jaays83FI37LiRZmIsEeGhJE3XsFBY11U0ZGVoERwInSBhAGMYwANWOPLZP36/0Yu7\ne+a+Zua65p7D8/l4zGPu6/qdvtd1X7/HcL/4/b53dXcAAAAA2LfdZ7kHAAAAAMDyE4kAAAAAEIkA\nAAAAEIkAAAAAiEgEAAAAQEQiAAAAACISAcA+q6oeWVUXV9VXqur05R7PLFXVkVW1YY77P7OqfnXi\n8X+oqn+sqq9W1f7j3985h+Ouq6ojZ73feZr39wIAmB2RCIB9VlV9rKruqKr7L/dYlsmJSW5L8tDu\nfvXChVV1blW9cdcP65vHf1lVfXK5jr8t3X1Sd5+WJFV13yS/l+QHu/vB3b1p/Pu6nTnGYu9/dz+1\nuz+2M/udt6rqqnrCnPY9s89EVf1DVb1gFvtasN83VNW7Zr1fANgVRCIA9klV9bgk35Okk/zILj72\nyl15vG14bJKru7vnsfPd6HXO2yOTPCDJuuUeCADAzhCJANhXnZDk0iTnJvmZyQVV9W1VdXpVfaGq\nvlRVn6yqbxuXPa+qLqmqO6vqxqp62fj8x6rq5yb2ca8rHsarK15ZVZ9P8vnxud8f9/Hlqrq8qr5n\nYv0VVfXaqvr78Xawy6vqoKo6Y+GtYVV1flX90mIvsqq+u6ouG1/HZVX13ePzW173a8Zbo16wYLsT\nk7xkYvkHx+dPnRjT1VX1Ywte899U1ZuqalOSN4yv4/Squq2qrq+qk8f3YuW4zcOq6o+r6paquqmq\n3jhu85QkZyb5rvH4d27l9T2iqv6kqm4erwr7wFbW29a4n1BVHx/fo9uq6s/H52t8LbeO36Orqupp\nW96/caxPTHLtuKs7q+qjE9/vJ4xfb+vz9N6q+uL4/MVV9dQl3v9vXv1SVfevqjePr/3m8ev7j8uO\nrKoNVfXqcfy3VNXLF3tvxvUfPX6Obq+q9VX18xPL3lBV76mqd4zv37qqWrOV/Vw8fvmZcdw/NbFs\n0bGMr+N3q+qGGm7ZO3PL+7Ng34t+Jra1fVUdUFV/VcP5entVfaKq7lNV70zymCQfHPf1mkWOt+i2\nE+/X+6pq4/i5/k/j80cleW2Snxr3+5mtvecAsDsSiQDYV52Q5E/HPy+sqkdOLPvdJM9O8t1JHpHk\nNUnuqarHJvlQkj9IsirJM5NcsR3H/NEkRyQ5dHx82biPRyT5syTvraoHjMv+c5LjkxyT5KFJfjbJ\n15K8PcnxEz+sHpDkBeP291JVj0jy10nekmT/DLdE/XVV7d/dLxtf+++Mt0Z9ZHLb7j5rwfIfHhf9\nfYYrsB6W5L8leVdVPWpi0yOSXJfh6ppfT/LzSY4eX+ezxvdg0rlJNid5QpJ/k+QHk/xcd1+T5KQk\nnxqPv9/ib2nemeSBSZ6a5NuTvGkr621r3KcluSjJw5McmOH7m3Es35vkieN2P5lk04L36XPjsZNk\nv+7+/kWOvejnaVz2oSSHjGP/2wzv+bbe/0n/NclzM7y3hyU5PMmvTCz/jnHcq5O8IskZVfXwRd+d\n5LwkG5I8OsmPJ/mNqpp8LT8yrrNfkvOTvHWxnXT3945fHjaO+8+nGMtvZXiPn5nhc7A6yesW2ffW\nPhPb2v7V4+taleEz+dphV/3SJDck+eFxX7+zyMtZdNvx3Ptgks+Mx/qBJL9YVS/s7g8n+Y0kfz7u\n97DF3icA2F2JRADsc6rqeRlutXpPd1+eISC8eFx2nwxB5lXdfVN3f6O7L+nufxnX+Uh3v7u7vz7O\nPbM9keg3u/v27v6nJOnud4372Nzdpye5f5Injev+XJJf6e5re/CZcd1PJ/lShh9Mk+S4JB/r7n9c\n5Hg/lOTz3f3O8RjvTvJ3SRYLDlPp7vd2983dfc8YAD6fIU5scXN3/8F4vH/KEFZ+v7s3dPcdGX6g\nTzJMnJ0hgv1id9/V3bdmiDzHTTOWMfIcneSk7r5j/J58fAfG/fUMn4dHd/c/d/cnJ55/SJInJ6nu\nvqa7b5lmbBNj3NbnKd19Tnd/ZXz8hiSHVdXDptz9S5L8Wnff2t0bM8Svl04s//q4/OvdfUGSr+Zb\nn6/JMR6U5N8mOWV8/VckOTtDSN3ik919QXd/I0OY2974sehYqqoyzI31S+O58ZUMkWXaz8BS2389\nyaOSPHY89ie24/bKrW37nCSruvvXuvvuce6pP5p2zACwOxOJANgX/UySi7r7tvHxn+Vbt5wdkGF+\nmb9fZLuDtvL8tG6cfFBVv1xV14y3Gt2Z4UqLA6Y41tuT/PT49U9n+KF9MY9O8oUFz30hw9UPO6Sq\nTqiqK8ZbcO5M8rSJMScLXuM4hhu3svyxSe6b5JaJ/f2PDFfVTOOgJLeP8Wlnxv2aJJXk0+OtVD+b\nJN390QxXzJyR5NaqOquqHjrl2LbY6uephtvqfquG2+C+nOQfJraZxsLv7xfG57bY1N2bJx5/LcmD\nt7KfLYFlcl+Tn5MvLtjPA2r75pza2lhWZbgS7PKJ782Hx+ensdT2/z3J+iQXVdV1VXXqdox5a9s+\nNsmjtxxvPOZrM1xtBAB7tH1lQkkASDLMD5Ph6pYVVbXlB9/7J9mvqg5LclWSf07y+Ay3k0y6Mfe+\nambSXRl+WN3iOxZZ55tXMNQw/9BrMlwRtK6776mqOzLEii3HenySzy6yn3cl+ew43qckWXQeniQ3\nZ/iBdtJjMvwQPY17XXEx3m73R+OYP9Xd36iqKybG/K+2SXJLhlu4tjho4usbk/xLkgMWBISt7Wuh\nG5M8oqr26+5F5yyaZtzd/cUMt8VtucrsI1V1cXev7+63JHlLVX17kvck+S9JfnWJcU26LVv/PL04\nybEZbhf8hwyRcPIzsNTr3/L93TJh9mPG57bXzRnex4dMhKLHJLlpB/a1vW5L8k9Jntrd0xxv4Xuy\nze3H1/PqJK+uYT6pj1bVZd39vxfZ11TbZvjcXd/dh0w5RgDYY7iSCIB9zY8m+UaGeYGeOf55SpJP\nJDmhu+9Jck6S3xsnp11RVd9Vw4TAf5rkBVX1k1W1sqr2r6pnjvu9Ism/r6oH1jBh8SuWGMdDMszF\nszHJyqp6XYa5h7Y4O8lpVXVIDZ5RVfsnSXdvyDCf0TuTvG/L7WuLuCDJE6vqxeN4f2p83X815Xv1\nj0m+c+LxgzL8ALwxSWqYfPhpS+zjPUleVVWrq2q/JKdsWTDeunVRktOr6qHjhMKPr6rnTxz/wKq6\n32I7Hrf/UJK3VdXDq+q+VfW9i6y6zXFX1U9U1ZaQdce47j1V9ZyqOqKGX3F/V4bYc0+2wxKfp4dk\niGSbMgTG31iw+cL3f6F3J/mVqlo1zk31ugwBcbt0941JLknym1X1gKp6RobP747+Gvelxj157Hsy\nBLw3jSEu42flhdvY9zc/E0ttX1UvqmFi8spwm+Y38q3v4TbHuY1tP53kK1V1Sg2Tkq+oqqdV1XMm\n9vu48VZDANij+McLgH3NzyT5k+6+obu/uOVPhtuKXjLeQvPLGa4ouizJ7Ul+O8l9uvuGDHPovHp8\n/op8a26WNyW5O8MPiG/POAHxNlyY4Yqez2W4teefc+9bsX4vQ2C5KMmXk/xxksnf+PT2JE/P1m81\nS3dvSvKicbybMly59KKJ2+yW8sdJDh1vqflAd1+d5PQkn8rwOp+e5G+W2Mcfja/hyiT/L0O42pzh\nB+5kmPfmfkmuzhBo/iLDPDBJ8tEMV8l8saq2NuaXZpg75u+S3JrkFxeuMMW4n5Pk/1bVVzNMyvyq\ncZ6Zh47jvyPD92hThluQttein6ck7xj3e1OG13/pgu3u9f4vst83Jlmb4b29KsPE12/cgfElwyTp\nj8twVdH/TPL6XjCZ+XZ4Q5K3j+P+ySnWPyXDbV2XjrfdfSSLzJ00Wuwzsa3tDxkffzXD9/9t3f1/\nxmW/mSGy3VlVv7zIsRbddpyX6UUZAvP1Ga5mOjvDlWBJ8t7x701V9bdTvH4A2G3U9HP3AQC7i/GK\nmXdlmFR3j/nHvKqOTnJmdy+8DQ4AgGXmSiIA2MOMtz+9KsnZu3sgGm/HOWa83W11ktdnuFIFAIDd\nzJKRqKrOqapbq2qxiTMzzpPwlqpaX1VXVtWzZj9MACBJquopSe7McEvWm5d5ONOoDL+a/Y4Mt5td\nk2HuHAAAdjNL3m42Xs7+1STv6O5/NTllVR2T5BcyzNFwRJLf7+4j5jBWAAAAAOZkySuJuvviDJMs\nbs2xGQJSd/elGX6F8KO2sT4AAAAAu5mVM9jH6tz7t7FsGJ+7ZeGKVXVikhOT5EEPetCzn/zkJ8/g\n8AAAAAAkyeWXX35bd6/akW1nEYmm1t1nJTkrSdasWdNr167dlYcHAAAA2KtV1Rd2dNtZ/Hazm5Ic\nNPH4wPE5AAAAAPYQs4hE5yc5YfwtZ89N8qXu/le3mgEAAACw+1rydrOqeneSI5McUFUbkrw+yX2T\npLvPTHJBht9stj7J15K8fF6DBQAAAGA+loxE3X38Ess7yStnNiIAAAAAdrlZ3G4GAAAAwB5OJAIA\nAABAJAIAAABAJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAA\nAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIA\nAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEA\nAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkA\nAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgE\nAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQi\nAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACIS\nAQAAABCRCAAAAICIRAAAAABkykhUVUdV1bVVtb6qTl1k+cOq6oNV9ZmqWldVL5/9UAEAAACYlyUj\nUVWtSHJGkqOTHJrk+Ko6dMFqr0xydXcfluTIJKdX1f1mPFYAAAAA5mSaK4kOT7K+u6/r7ruTnJfk\n2AXrdJKHVFUleXCS25NsnulIAQAAAJibaSLR6iQ3TjzeMD436a1JnpLk5iRXJXlVd9+zcEdVdWJV\nra2qtRs3btzBIQMAAAAwa7OauPqFSa5I8ugkz0zy1qp66MKVuvus7l7T3WtWrVo1o0MDAAAAsLOm\niUQ3JTlo4vGB43OTXp7k/T1Yn+T6JE+ezRABAAAAmLdpItFlSQ6pqoPHyaiPS3L+gnVuSPIDSVJV\nj0zypCTXzXKgAAAAAMzPyqVW6O7NVXVykguTrEhyTnevq6qTxuVnJjktyblVdVWSSnJKd982x3ED\nAAAAMENLRqIk6e4Lklyw4LkzJ76+OckPznZoAAAAAOwqs5q4GgAAAIA9mEgEAAAAgEgEAAAAgEgE\nAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQi\nAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACIS\nAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCR\nCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICI\nRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABE\nJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAg\nIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAA\nEYkAAAAAyJSRqKqOqqprq2p9VZ26lXWOrKorqmpdVX18tsMEAAAAYJ5WLrVCVa1IckaSf5dkQ5LL\nqur87r56Yp39krwtyVHdfUNVffu8BgwAAADA7E1zJdHhSdZ393XdfXeS85Icu2CdFyd5f3ffkCTd\nfetshwkAAADAPE0TiVYnuXHi8YbxuUlPTPLwqvpYVV1eVScstqOqOrGq1lbV2o0bN+7YiAEAAACY\nuVlNXL0yybOT/FCSFyb51ap64sKVuvus7l7T3WtWrVo1o0MDAAAAsLOWnJMoyU1JDpp4fOD43KQN\nSTZ1911J7qqqi5McluRzMxklAAAAAHM1zZVElyU5pKoOrqr7JTkuyfkL1vnLJM+rqpVV9cAkRyS5\nZrZDBQAAAGBelrySqLs3V9XJSS5MsiLJOd29rqpOGpef2d3XVNWHk1yZ5J4kZ3f3Z+c5cAAAAABm\np7p7WQ68Zs2aXrt27bIcGwAAAGBvVFWXd/eaHdl2VhNXAwAAALAHE4kAAAAAEIkAAAAAEIkAAAAA\niEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAA\nQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAA\nACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAA\nABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAA\nAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAA\nAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIA\nAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEA\nAAAAEYkAAAAAyJSRqKqOqqprq2p9VZ26jfWeU1Wbq+rHZzdEAAAAAOZtyUhUVSuSnJHk6CSHJjm+\nqg7dynq/neSiWQ8SAAAAgPma5kqiw5Os7+7ruvvuJOclOXaR9X4hyfuS3DrD8QEAAACwC0wTiVYn\nuXHi8YbxuW+qqtVJfizJH25rR1V1YlWtraq1Gzdu3N6xAgAAADAns5q4+s1JTunue7a1Unef1d1r\nunvNqlWrZnRoAAAAAHbWyinWuSnJQROPDxyfm7QmyXlVlSQHJDmmqjZ39wdmMkoAAAAA5mqaSHRZ\nkkOq6uAMcei4JC+eXKG7D97ydVWdm+SvBCIAAACAPceSkai7N1fVyUkuTLIiyTndva6qThqXnznn\nMQIAAAAwZ9NcSZTuviDJBQueWzQOdffLdn5YAAAAAOxKs5q4GgAAAIA9mEgEAAAAgEgEAAAAgEgE\nAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQi\nAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACIS\nAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCR\nCAAAAICIRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICI\nRAAAAABEJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABE\nJAIAAAAgIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAg\nIhEAAAAAEYkAAAAAiEgEAAAAQEQiAAAAACISAQAAABCRCAAAAICIRAAAAABEJAIAAAAgIhEAAAAA\nEYkAAAAAyJSRqKqOqqprq2p9VZ26yPKXVNWVVXVVVV1SVYfNfqgAAAAAzMuSkaiqViQ5I8nRSQ5N\ncnxVHbpgteuTPL+7n57ktCRnzXqgAAAAAMzPNFcSHZ5kfXdf1913JzkvybGTK3T3Jd19x/jw0iQH\nznaYAAAAAMzTNJFodZIbJx5vGJ/bmlck+dBiC6rqxKpaW1VrN27cOP0oAQAAAJirmU5cXVXflyES\nnbLY8u4+q7vXdPeaVatWzfLQAAAAAOyElVOsc1OSgyYeHzg+dy9V9YwkZyc5urs3zWZ4AAAAAOwK\n01xJdFmSQ6rq4Kq6X5Ljkpw/uUJVPSbJ+5O8tLs/N/thAgAAADBPS15J1N2bq+rkJBcmWZHknO5e\nV1UnjcvPTPK6JPsneVtVJcnm7l4zv2EDAAAAMEvV3cty4DVr1vTatWuX5dgAAAAAe6OqunxHL9yZ\n6cTVAAAAAOyZRCIAAAAARCIAAAAARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAA\nAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAA\nAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQA\nAABARCIAAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIA\nAAAAIhIBAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIB\nAAAAEJEIAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEI\nAAAAgIhEAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABARCIAAAAAIhIBAAAAEJEIAAAAgIhE\nAAAAAEQkAgAAACAiEQAAAAARiQAAAACISAQAAABApoxEVXVUVV1bVeur6tRFlldVvWVcfmVVPWv2\nQwUAAABgXpaMRFW1IskZSY5OcmiS46vq0AWrHZ3kkPHPiUn+cMbjBAAAAGCOprmS6PAk67v7uu6+\nO8l5SY5dsM6xSd7Rg0uT7FdVj5rxWAEAAACYk5VTrLM6yY0TjzckOWKKdVYnuWVypao6McOVRkny\nL1X12e0aLTALByS5bbkHAfso5x8sD+ceLA/nHiyPJ+3ohtNEopnp7rOSnJUkVbW2u9fsyuMDzj1Y\nTs4/WB7OPVgezj1YHlW1dke3neZ2s5uSHDTx+MDxue1dBwAAAIDd1DSR6LIkh1TVwVV1vyTHJTl/\nwTrnJzlh/C1nz03ype6+ZeGOAAAAANg9LXm7WXdvrqqTk1yYZEWSc7p7XVWdNC4/M8kFSY5Jsj7J\n15K8fIpjn7XDowZ2hnMPlo/zD5aHcw+Wh3MPlscOn3vV3bMcCAAAAAB7oGluNwMAAABgLycSAQAA\nADD/SFRVR1XVtVW1vqpOXWR5VdVbxuVXVtWz5j0m2BdMce69ZDznrqqqS6rqsOUYJ+xtljr3JtZ7\nTlVtrqof35Xjg73VNOdeVR1ZVVdU1bqq+viuHiPsrab4786HVdUHq+oz4/k3zRy2wDZU1TlVdWtV\nfXYry3eotcw1ElXViiRnJDk6yaFJjq+qQxesdnSSQ8Y/Jyb5w3mOCfYFU5571yd5fnc/PclpMbEg\n7LQpz70t6/12kot27Qhh7zTNuVdV+yV5W5If6e6nJvmJXT5Q2AtN+W/fK5Nc3d2HJTkyyenjb84G\ndty5SY7axvIdai3zvpLo8CTru/u67r47yXlJjl2wzrFJ3tGDS5PsV1WPmvO4YG+35LnX3Zd09x3j\nw0uTHLiLxwh7o2n+3UuSX0jyviS37srBwV5smnPvxUne3903JEl3O/9gNqY5/zrJQ6qqkjw4ye1J\nNu/aYcLepbsvznAubc0OtZZ5R6LVSW6ceLxhfG571wG2z/aeV69I8qG5jgj2DUuee1W1OsmPxZWz\nMEvT/Lv3xCQPr6qPVdXlVXXCLhsd7N2mOf/emuQpSW5OclWSV3X3PbtmeLDP2qHWsnJuwwH2CFX1\nfRki0fOWeyywj3hzklO6+57hf6gCu8jKJM9O8gNJvi3Jp6rq0u7+3PIOC/YJL0xyRZLvT/L4JP+r\nqj7R3V9e3mEBC807Et2U5KCJxweOz23vOsD2meq8qqpnJDk7ydHdvWkXjQ32ZtOce2uSnDcGogOS\nHFNVm7v7A7tmiLBXmubc25BkU3ffleSuqro4yWFJRCLYOdOcfy9P8lvd3UnWV9X1SZ6c5NO7Zoiw\nT9qh1jLv280uS3JIVR08Tkx2XJLzF6xzfpITxpm3n5vkS919y5zHBXu7Jc+9qnpMkvcnean/iwoz\ns+S5190Hd/fjuvtxSf4iyX8UiGCnTfPfnH+Z5HlVtbKqHpjkiCTX7OJxwt5omvPvhgxX8aWqHpnk\nSUmu26WjhH3PDrWWuV5J1N2bq+rkJBcmWZHknO5eV1UnjcvPTHJBkmOSrE/ytQyVGdgJU557r0uy\nf5K3jVc0bO7uNcs1ZtgbTHnuATM2zbnX3ddU1YeTXJnkniRnd/eivzYYmN6U//adluTcqroqSWW4\n7fq2ZRs07AWq6t0ZflvgAVW1Icnrk9w32bnWUsMVfwAAAADsy+Z9uxkAAAAAewCRCAAAAACRCAAA\nAACRCAD9Lvo6AAAAHUlEQVQAAICIRAAAAABEJAIAAAAgIhEAAAAASf4/LK48+d9tMjkAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0af5ddc7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 0\n",
    "k = 100\n",
    "plt.title(\"Accuracy of target classification on the test set\")\n",
    "plt.plot(iter_list[k+start:-k], smooth(accuracy_list[start:]), label=\"Validation accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_target_predict = np.argmax(sess.run(tf.nn.softmax(DG_t2s_classif), feed_dict={ipt_target: X_target_test[0:1000]}), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[[0 0 0 ..., 1 0 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[7 2 1 ..., 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(y)\n",
    "print(Y_target_test)\n",
    "y=np.argmax(Y_target_test,axis=1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59199999999999997"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1=y[0:1000]\n",
    "accuracy_score(y1, Y_target_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Gradient of D with respect to\", ipt_source)\n",
    "gradient = sess.run(tf.gradients(discriminator(ipt_source, \"source\")[1], ipt_source), \n",
    "                    feed_dict={ipt_source: sample_source})\n",
    "print(\"Min:\", np.array(np.abs(gradient)).min())\n",
    "print(\"Max:\", np.array(gradient).max())\n",
    "print(\"Avg:\", np.array(np.abs(gradient)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Gradient of D with respect to\", ipt_target)\n",
    "gradient = sess.run(tf.gradients(discriminator(ipt_target, \"target\")[1], ipt_target), \n",
    "                    feed_dict={ipt_target: sample_target})\n",
    "\n",
    "print(\"Min:\", np.array(gradient).min())\n",
    "print(\"Max:\", np.array(gradient).max())\n",
    "print(\"Avg:\", np.array(np.abs(gradient)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = 1\n",
    "print(\"Gradient with respect to\", G_s2t_vars[ind])\n",
    "gradient = sess.run(tf.gradients(G_s2t_loss, G_s2t_vars[ind]), feed_dict={ipt_source: sample_source, \n",
    "                                                                          ipt_target: sample_target})\n",
    "print(\"Min:\", np.array(gradient).min())\n",
    "print(\"Max:\", np.array(gradient).max())\n",
    "print(\"Avg:\", np.array(gradient).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = 2\n",
    "print(\"Gradient with respect to\", G_t2s_vars[ind])\n",
    "gradient = sess.run(tf.gradients(G_t2s_loss, G_t2s_vars[ind]), feed_dict={ipt_source: sample_source, \n",
    "                                                                          ipt_target: sample_target})\n",
    "print(\"Min:\", np.array(gradient).min())\n",
    "print(\"Max:\", np.array(gradient).max())\n",
    "print(\"Avg:\", np.array(gradient).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
